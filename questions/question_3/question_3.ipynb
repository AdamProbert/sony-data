{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "> Assumption: The required output format is `tsv`, matching the input format.\n",
    "\n",
    "\n",
    "Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/07 17:24:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"question_3\").config(\"spark.driver.memory\", \"4g\").getOrCreate()\n",
    "\n",
    "PART_A_OUTPUT = \"./output/part_a\"\n",
    "PART_B_OUTPUT = \"./output/part_b\"\n",
    "PART_C_OUTPUT = \"./output/part_c\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial analysis of tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+------------------------------------+-----------+--------+------------------------------------------+\n",
      "|user_id    |timestamp          |artist_id                           |artist_name|track_id|track_name                                |\n",
      "+-----------+-------------------+------------------------------------+-----------+--------+------------------------------------------+\n",
      "|user_000001|2009-05-05 00:08:57|f1b1cf71-bd35-4e99-8624-24a6e15f133a|Deep Dish  |null    |Fuck Me Im Famous (Pacha Ibiza)-09-28-2007|\n",
      "|user_000001|2009-05-04 14:54:10|a7f7df4a-77d8-4f12-8acd-5c60c93f4de8|坂本龍一   |null    |Composition 0919 (Live_2009_4_15)         |\n",
      "|user_000001|2009-05-04 14:52:04|a7f7df4a-77d8-4f12-8acd-5c60c93f4de8|坂本龍一   |null    |Mc2 (Live_2009_4_15)                      |\n",
      "|user_000001|2009-05-04 14:42:52|a7f7df4a-77d8-4f12-8acd-5c60c93f4de8|坂本龍一   |null    |Hibari (Live_2009_4_15)                   |\n",
      "|user_000001|2009-05-04 14:42:11|a7f7df4a-77d8-4f12-8acd-5c60c93f4de8|坂本龍一   |null    |Mc1 (Live_2009_4_15)                      |\n",
      "+-----------+-------------------+------------------------------------+-----------+--------+------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- track_id: string (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/07 17:24:39 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 3:===================================================>     (17 + 2) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------------------------+-----------------------------+------------------------------------+-----------------------------+\n",
      "|summary|user_id    |artist_id                           |artist_name                  |track_id                            |track_name                   |\n",
      "+-------+-----------+------------------------------------+-----------------------------+------------------------------------+-----------------------------+\n",
      "|count  |19150868   |18548702                            |19150868                     |16982280                            |19150867                     |\n",
      "|mean   |null       |null                                |Infinity                     |null                                |NaN                          |\n",
      "|stddev |null       |null                                |NaN                          |null                                |NaN                          |\n",
      "|min    |user_000001|00010eb3-ebfe-4965-81ef-0ac64cd49fde|! Europe - France - Cold Wave|00000891-ca9c-490c-9fae-fff04957c9ef|\u001b戀上你是書中主角 The Library|\n",
      "|max    |user_001000|ffff44bd-e5a5-4e87-8700-35481264e37d|￼                            |ffffff64-4a90-4350-9281-c9dc10aa9d30|���                          |\n",
      "+-------+-----------+------------------------------------+-----------------------------+------------------------------------+-----------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "track_path = \"../../data/userid-timestamp-artid-artname-traid-traname.tsv\"\n",
    "track_df = spark.read.csv(track_path, sep=r\"\\t\", header=False, inferSchema=True)\n",
    "track_df = track_df.withColumnsRenamed(\n",
    "    {\n",
    "        \"_c0\": \"user_id\",\n",
    "        \"_c1\": \"timestamp\",\n",
    "        \"_c2\": \"artist_id\",\n",
    "        \"_c3\": \"artist_name\",\n",
    "        \"_c4\": \"track_id\",\n",
    "        \"_c5\": \"track_name\",\n",
    "    }\n",
    ")\n",
    "track_df.show(5, truncate=False)\n",
    "track_df.printSchema()\n",
    "track_df.describe().show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe cleanup\n",
    "The previous describe shows different count values across the columns indicating null values.\n",
    "Lets remove rows with any null values, providing a complete dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>     (17 + 2) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------------------------+-------------+------------------------------------+-----------------+\n",
      "|summary|user_id    |artist_id                           |artist_name  |track_id                            |track_name       |\n",
      "+-------+-----------+------------------------------------+-------------+------------------------------------+-----------------+\n",
      "|count  |16982280   |16982280                            |16982280     |16982280                            |16982280         |\n",
      "|mean   |null       |null                                |Infinity     |null                                |NaN              |\n",
      "|stddev |null       |null                                |NaN          |null                                |NaN              |\n",
      "|min    |user_000001|00011101-560b-4c98-8cec-60b545a160b5|!Action Pact!|00000891-ca9c-490c-9fae-fff04957c9ef|!                |\n",
      "|max    |user_001000|fffed9ff-98c6-458a-8379-47e7fb4ba6ec|푸른새벽     |ffffff64-4a90-4350-9281-c9dc10aa9d30|～Toxic Gorilla～|\n",
      "+-------+-----------+------------------------------------+-------------+------------------------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "track_df = track_df.na.drop()\n",
    "track_df.describe().show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\"Create a list of user IDs, along with the number of distinct songs each user has played.\"\n",
    "\n",
    "An aggregation on `user_id` and count distinct `track_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+\n",
      "|    user_id|distinct_song_count|\n",
      "+-----------+-------------------+\n",
      "|user_000691|              59850|\n",
      "|user_000861|              43860|\n",
      "|user_000681|              36746|\n",
      "|user_000800|              31872|\n",
      "|user_000774|              29997|\n",
      "+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "distinct_songs_per_user_df = track_df.groupBy(\"user_id\")\\\n",
    "    .agg(f.countDistinct(\"track_id\").alias(\"distinct_song_count\"))\\\n",
    "    .orderBy(f.col(\"distinct_song_count\").desc())\n",
    "\n",
    "distinct_songs_per_user_df.show(5)\n",
    "\n",
    "# Export the dataframe to a single tsv file\n",
    "distinct_songs_per_user_df.coalesce(1)\\\n",
    "    .write\\\n",
    "    .option(\"sep\", \"\\t\")\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .csv(PART_A_OUTPUT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\"Create a list of the 100 most popular songs (artist and title) in the dataset, with the number\n",
    "of times each was played.\"\n",
    "\n",
    "A `group_by` on `artist_name` and `track_name` with an aggregate count of all rows, ordered in descending order and limited to the top 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+\n",
      "|        artist_name|          track_name|count|\n",
      "+-------------------+--------------------+-----+\n",
      "| The Postal Service|  Such Great Heights| 3992|\n",
      "|       Boy Division|Love Will Tear Us...| 3663|\n",
      "|          Radiohead|        Karma Police| 3534|\n",
      "|               Muse|Supermassive Blac...| 3483|\n",
      "|Death Cab For Cutie|     Soul Meets Body| 3479|\n",
      "+-------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "popular_songs_df = track_df.select(\"artist_name\", \"track_name\")\\\n",
    "    .groupBy(\"artist_name\", \"track_name\")\\\n",
    "    .agg(f.count(\"*\").alias(\"count\"))\\\n",
    "    .orderBy(f.col(\"count\").desc())\\\n",
    "    .limit(100)\n",
    "\n",
    "popular_songs_df.show(5)\n",
    "\n",
    "# Export the dataframe to a single tsv file\n",
    "popular_songs_df.coalesce(1)\\\n",
    "    .write\\\n",
    "    .option(\"sep\", \"\\t\")\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .csv(PART_B_OUTPUT)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C\n",
    "\"Say we define a user’s “session” of Last.fm usage to be comprised of one or more songs\n",
    "played by that user, where each song is started within 20 minutes of the previous song’s\n",
    "start time.\n",
    "Create a list of the top 10 longest sessions (by elapsed time), with the following information\n",
    "about each session: userid, timestamp of first and last songs in the session, and the list of\n",
    "songs played in the session (in order of play).\"\n",
    "\n",
    "This query required the use of a window function to group user sessions while retaining the other required fields.\n",
    "I've provided comments below describing individual commands, I'll also summarise here.\n",
    "\n",
    "1. Determine the time difference between x played track and x-1 played track utilising a window function to encapsulate individual users.\n",
    "2. Label the start track of a new session using a session flag where the previous track was played more than 20 minutes ago.\n",
    "3. Add a new column tracking the session_id (per user) that increments for every session flag using `sum`.\n",
    "4. Aggregate dataframe to return user sessions with start and end times and songs played.\n",
    "5. Calculate the elapsed time for a session and order by this value in descending order, limiting to the top 10 longest sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-------------------+--------------------+\n",
      "|    user_id| session_start_time|   session_end_time|        songs_played|\n",
      "+-----------+-------------------+-------------------+--------------------+\n",
      "|user_000949|2006-02-12 17:49:31|2006-02-27 11:29:37|[Chained To You,T...|\n",
      "|user_000949|2007-05-01 03:41:15|2007-05-14 01:05:52|[White Daisy Pass...|\n",
      "|user_000949|2005-12-09 08:26:38|2005-12-18 04:40:04|[Neighborhood #2 ...|\n",
      "|user_000949|2005-11-11 03:30:37|2005-11-18 22:47:26|[Excuse Me Miss A...|\n",
      "|user_000949|2006-03-18 23:04:14|2006-03-26 19:13:45|[Disco Science,He...|\n",
      "+-----------+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "SESSION_DURATION_S = 1200\n",
    "\n",
    "# Limit the dataframe to only the required columns aiming to increase performance.\n",
    "session_df = track_df.select(\"user_id\", \"timestamp\", \"track_name\")\n",
    "\n",
    "# Specify the window for grouping users\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(\"timestamp\")\n",
    "\n",
    "# Calculate the time difference between current and previous row timestamp in seconds\n",
    "session_df = session_df.withColumn(\"time_diff_seconds\", f.col(\"timestamp\").cast(\"long\") - f.lag(f.col(\"timestamp\").cast(\"long\"), 1).over(window_spec))\n",
    "\n",
    "# Calculate the session flag (1 if new session, 0 otherwise)\n",
    "session_flag_calculator = f.when((f.col(\"time_diff_seconds\").isNull()) | (f.col(\"time_diff_seconds\") > SESSION_DURATION_S), 1).otherwise(0)\n",
    "session_df = session_df.withColumn(\"session_flag\", session_flag_calculator)\n",
    "\n",
    "# Calculate the session ID by summing the session flags for user window\n",
    "session_df = session_df.withColumn(\"session_id\", f.sum(\"session_flag\").over(window_spec))\n",
    "\n",
    "# Remove unnecessary columns\n",
    "session_df = session_df.drop(\"session_flag\")\n",
    "\n",
    "# Return a new dataframe of user sessions with start and end times and songs played grouped by user and session\n",
    "longest_sessions_df = session_df.groupBy(\"user_id\", \"session_id\").agg(\n",
    "    f.min(\"timestamp\").alias(\"session_start_time\"),\n",
    "    f.max(\"timestamp\").alias(\"session_end_time\"),\n",
    "    f.collect_list(f.col(\"track_name\")).alias(\"songs_played\")\n",
    ")\n",
    "\n",
    "# Calculate the elapsed time for each user session\n",
    "longest_sessions_df = longest_sessions_df.withColumn(\"elapsed_time\", (f.col(\"session_end_time\").cast(\"long\") - f.col(\"session_start_time\").cast(\"long\")))\n",
    "\n",
    "# Sort the sessions by elapsed time in descending order and select the top 10 longest sessions\n",
    "longest_sessions_df = longest_sessions_df.orderBy(f.col(\"elapsed_time\").desc()).limit(10)\n",
    "\n",
    "# Due to the songs_played column being an array, we need to convert it to string to be able to write it to a tsv file.\n",
    "def array_to_string(my_list):\n",
    "    return '[' + ','.join([str(elem) for elem in my_list]) + ']'\n",
    "\n",
    "array_to_string_udf = f.udf(array_to_string, StringType())\n",
    "longest_sessions_df = longest_sessions_df.withColumn('songs_played', array_to_string_udf(longest_sessions_df[\"songs_played\"]))\n",
    "\n",
    "# Remove unnecessary columns\n",
    "longest_sessions_df = longest_sessions_df.drop(\"elapsed_time\", \"session_id\")\n",
    "\n",
    "longest_sessions_df.show(5)\n",
    "\n",
    "# Export the dataframe to a single tsv file\n",
    "longest_sessions_df.coalesce(1)\\\n",
    "    .write\\\n",
    "    .option(\"sep\", \"\\t\")\\\n",
    "    .option(\"encoding\", \"UTF-8\")\\\n",
    "    .csv(PART_C_OUTPUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sony-data-DS4-90rM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
